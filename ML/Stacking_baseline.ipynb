{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀모델의 예측 결과 혼합을 통한 최종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_pred(preds):\n",
    "    for key in preds.keys():\n",
    "        pred_value = preds[key]\n",
    "        mse = mean_squared_error(y_test , pred_value)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print('{0} 모델의 RMSE: {1}'.format(key, rmse))\n",
    "\n",
    "# 개별 모델의 학습\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "# 개별 모델 예측\n",
    "ridge_pred = ridge_reg.predict(X_test)\n",
    "lasso_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "# 개별 모델 예측값 혼합으로 최종 예측값 도출\n",
    "pred = 0.4 * ridge_pred + 0.6 * lasso_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'Ridge': ridge_pred,\n",
    "         'Lasso': lasso_pred}\n",
    "#최종 혼합 모델, 개별모델의 RMSE 값 출력\n",
    "get_rmse_pred(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost와 lightGBM 혼합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_reg = XGBRegressor(n_estimators=1000, learning_rate=0.05, \n",
    "                       colsample_bytree=0.5, subsample=0.8)\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "lgbm_reg.fit(X_train, y_train)\n",
    "xgb_pred = xgb_reg.predict(X_test)\n",
    "lgbm_pred = lgbm_reg.predict(X_test)\n",
    "\n",
    "pred = 0.5 * xgb_pred + 0.5 * lgbm_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'XGBM': xgb_pred,\n",
    "         'LGBM': lgbm_pred}\n",
    "        \n",
    "get_rmse_pred(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스태킹 앙상블 모델을 통한 회귀 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stacking_base_datasets( )은 넘파이 ndarray를 인자로 사용하므로 DataFrame을 넘파이로 변환. \n",
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "# 각 개별 기반(Base)모델이 생성한 학습용/테스트용 데이터 반환. \n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_reg, X_train_n, y_train_n, X_test_n, 5)  \n",
    "lgbm_train, lgbm_test = get_stacking_base_datasets(lgbm_reg, X_train_n, y_train_n, X_test_n, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델이 반환한 학습 및 테스트용 데이터 세트를 Stacking 형태로 결합.  \n",
    "Stack_final_X_train = np.concatenate((ridge_train, lasso_train, \n",
    "                                      xgb_train, lgbm_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((ridge_test, lasso_test, \n",
    "                                     xgb_test, lgbm_test), axis=1)\n",
    "\n",
    "# 최종 메타 모델은 라쏘 모델을 적용. \n",
    "meta_model_lasso = Lasso(alpha=0.0005)\n",
    "\n",
    "#기반 모델의 예측값을 기반으로 새롭게 만들어진 학습 및 테스트용 데이터로 예측하고 RMSE 측정.\n",
    "meta_model_lasso.fit(Stack_final_X_train, y_train)\n",
    "final = meta_model_lasso.predict(Stack_final_X_test)\n",
    "mse = mean_squared_error(y_test , final)\n",
    "rmse = np.sqrt(mse)\n",
    "print('스태킹 회귀 모델의 최종 RMSE 값은:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ID = test['Id']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
